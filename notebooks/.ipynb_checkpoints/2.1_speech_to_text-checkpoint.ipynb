{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec552ce-000e-45af-8106-fe339b175d07",
   "metadata": {},
   "source": [
    "# Performing speech-to-text on files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e82174-8609-4f94-b35b-cbbd0c08e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f27672-9d1a-47a9-b3e0-7e2f73d60ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd6dc218-d61a-4f4c-87cb-bcfa77c260e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure user\n",
    "user = \"mitchel\"\n",
    "extracted_feats = True\n",
    "\n",
    "if user.lower() == \"jonas\":\n",
    "    BASE_PATH = Path(\"/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/\")\n",
    "elif user.lower() == \"mitchel\":\n",
    "#     BASE_PATH = Path(\"Z:/shares/ghep_lab/2021_VanhollebekeKappen_EEGStudy2_MIST_Cyberball_Audio/\")\n",
    "    BASE_PATH = Path(\"D:/Data/EEG_Study_2\")\n",
    "DATA_PATH = BASE_PATH.joinpath(\"Data/Raw/Audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79f2a8a-23d6-411e-bb0e-bc3da5bd2344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op de afbeeldingen afbeelding van een rekensom x door 72 keer 2 en dan 30 eten komen en dan denk ik dat ik eerst die andere twee samen heb genomen tot dat 31 uitkwam en dan kan ik zo even uit denk dat ik wel redelijk op mijn gemak was was het toch erg dat je snel snel denken maar wordt in ieder geval heerlijk rustig en de regels opgesteld dat het 72/2 met een breuk met een scherm wordt weergegeven te haakjes en dan datum 27 en 4 en dan lekker tegen en scherpe vraagteken\n"
     ]
    }
   ],
   "source": [
    "# https://www.thepythoncode.com/article/using-speech-recognition-to-convert-speech-to-text-python\n",
    "filename = \"D:/Data/EEG_Study_2/Data/Raw/Audio/ppt_8_mist_speech/audio_referential_control.wav\"\n",
    "\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# open the file\n",
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data, language=\"nl-NL\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e23a76f-b4e9-4d32-be7f-4ac4e1ceb2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ik zie op het scherm en rekenopgaven staan die staat op het bovenste deel van het scherm aan de rest van het scherm is wit de rekenopgaven omvat een deling eerst en vooral die tussen haakjes staat 72/2 daarna en daarna 2 aftrekkingen en met 27 en -4 sterren is gelijk aan teken en een vraagteken waarde het antwoord zou moeten komen de rekenopgaven is een vrij moeilijke rekenopgave aan moeilijker dan ik verwacht had om hier te zien te krijgen\n"
     ]
    }
   ],
   "source": [
    "# https://www.thepythoncode.com/article/using-speech-recognition-to-convert-speech-to-text-python\n",
    "filename = \"D:/Data/EEG_Study_2/Data/Raw/Audio/ppt_12_mist_speech/audio_referential_control.wav\"\n",
    "\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# open the file\n",
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data, language=\"nl-BE\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e9c9139-77d0-4042-920f-b0062b23a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mitch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mitch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\mitch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt') # Used for tags\n",
    "nltk.download('averaged_perceptron_tagger') # Used for tags\n",
    "nltk.download('brown') # Used for noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a267811-c05f-425b-92d0-d77bf62972ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(text)\n",
    "\n",
    "blob.tags\n",
    "\n",
    "blob.noun_phrases\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2872ee13-f284-4920-b4a3-92b469dac1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.06333333333333334, 0.4766666666666667)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now Dutch\n",
    "# https://github.com/gvisniuc/textblob-nl\n",
    "\n",
    "from textblob_nl import PatternTagger, PatternAnalyzer\n",
    "\n",
    "blob = TextBlob(text, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "\n",
    "# The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "blob.sentiment # Polarity, subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4fd4f81-13cd-4866-849e-9651269e8f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024691358024691357"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word count\n",
    "blob.word_counts['ik'] # For instance 'ik'\n",
    "\n",
    "# Relative word usage (proportional):\n",
    "blob.word_counts['ik']  / len(blob.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23667dcd-7a32-4afa-abec-bbce0d055298",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22780/4090242275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWavFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.wav\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m              \u001b[1;31m# use \"test.wav\" as the audio source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m                        \u001b[1;31m# extract audio data from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stress_study_lib\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# attempt to read the file as WAV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stress_study_lib\\lib\\wave.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stress_study_lib\\lib\\wave.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# else, assume it is an open file object already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.wav'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "with sr.WavFile(\"test.wav\") as source:              # use \"test.wav\" as the audio source\n",
    "    audio = r.record(source)                        # extract audio data from the file\n",
    "\n",
    "try:\n",
    "    list = r.recognize(audio,True, language=\"nl-BE\")                  # generate a list of possible transcriptions\n",
    "    print(\"Possible transcriptions:\")\n",
    "    for prediction in list:\n",
    "        print(\" \" + prediction[\"text\"] + \" (\" + str(prediction[\"confidence\"]*100) + \"%)\")\n",
    "except LookupError:                                 # speech is unintelligible\n",
    "    print(\"Could not understand audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d0bf1-31b1-49b6-9026-49d992dfd568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
